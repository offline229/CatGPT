import gradio as gr
import joblib
import librosa
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import moviepy.editor as mp

# 1. åŠ è½½ YAMNet é¢„è®­ç»ƒæ¨¡å‹
print("ğŸš€ åŠ è½½ YAMNet é¢„è®­ç»ƒæ¨¡å‹...")
local_model_path = "C:\\Users\\ç¾½è½\\.cache\\kagglehub\\models\\google\\yamnet\\tensorFlow2\\yamnet\\1"
yamnet_model = hub.load(local_model_path)
print("âœ… YAMNet åŠ è½½å®Œæˆï¼")

# 2. åŠ è½½åˆ†ç±»æ¨¡å‹ & PCA å˜æ¢
print("ğŸš€ åŠ è½½çŒ«å«åˆ†ç±»æ¨¡å‹ & PCA...")
model = joblib.load("voting_classifier.pkl")  # åŠ è½½å·²è®­ç»ƒå¥½çš„åˆ†ç±»å™¨
pca = joblib.load("pca_transform.pkl")  # åŠ è½½ PCA å˜æ¢
print("âœ… æ¨¡å‹ & PCA åŠ è½½æˆåŠŸï¼")

# 3. å®šä¹‰ç±»åˆ«æ˜ å°„
label_map = {
    0: "Angry",
    1: "Defence",
    2: "Fighting",
    3: "Happy",
    4: "HuntingMind",
    5: "Mating",
    6: "MotherCall",
    7: "Paining",
    8: "Resting",
    9: "Warning",
}

# 4. ç‰¹å¾æå–å‡½æ•°
def extract_features(file_path):
    """æå–éŸ³é¢‘ç‰¹å¾"""
    audio, sr = librosa.load(file_path, sr=16000)
    waveform = tf.convert_to_tensor(audio, dtype=tf.float32)
    scores, embeddings, spectrogram = yamnet_model(waveform)

    # **ä¿æŒå’Œè®­ç»ƒæ—¶ä¸€è‡´çš„ 2048 ç»´ç‰¹å¾**
    feature = np.concatenate([ 
        tf.reduce_mean(embeddings, axis=0).numpy(),
        tf.reduce_max(embeddings, axis=0).numpy()
    ])

    feature = feature.reshape(1, -1)  # ç¡®ä¿å½¢çŠ¶ä¸º (1, n)
    
    # **åº”ç”¨ PCA é™ç»´**
    feature = pca.transform(feature)  # è½¬æ¢ä¸º 256 ç»´
    return feature

# 5. MP4 è½¬ MP3 å‡½æ•° (æå–å‰ 4 ç§’çš„éŸ³é¢‘)
def convert_mp4_to_mp3(mp4_path, output_path="temp_audio.mp3"):
    """å°† MP4 è½¬æ¢ä¸º MP3 å¹¶æˆªå–å‰ 4 ç§’"""
    try:
        clip = mp.VideoFileClip(mp4_path)
        duration = clip.duration  # è·å–è§†é¢‘çš„æ€»æ—¶é•¿

        # å¦‚æœè§†é¢‘æ—¶é•¿å°äº 4 ç§’ï¼Œåˆ™æˆªå–æ•´ä¸ªè§†é¢‘çš„éŸ³é¢‘
        end_time = min(4, duration)

        # æˆªå–éŸ³é¢‘
        clip = clip.subclip(0, end_time)
        clip.audio.write_audiofile(output_path, codec='mp3')
        return output_path
    except Exception as e:
        print(f"âŒ é”™è¯¯å‘ç”Ÿï¼š{e}")
        return None

# 6. é¢„æµ‹å‡½æ•°
def predict_emotion(audio_file_path):
    """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹å¹¶è½¬æ¢ MP4 ä¸º MP3
        if audio_file_path.endswith(".mp4"):
            print("ğŸ“½ï¸ æ£€æµ‹åˆ° MP4 æ–‡ä»¶ï¼Œå¼€å§‹è½¬æ¢ä¸º MP3...")
            mp3_file_path = convert_mp4_to_mp3(audio_file_path)
            if mp3_file_path is None:
                return "Error: éŸ³é¢‘è½¬æ¢å¤±è´¥", 0.0
        else:
            mp3_file_path = audio_file_path
        
        feature = extract_features(mp3_file_path)
        predicted_label_idx = model.predict(feature)[0]  # é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•
        probabilities = model.predict_proba(feature)[0]  # é¢„æµ‹çš„æ¦‚ç‡
        max_prob = max(probabilities)  # æœ€é«˜æ¦‚ç‡å€¼

        # è·å–ç±»åˆ«åç§°
        predicted_label_text = label_map.get(predicted_label_idx, "Unknown")

        return predicted_label_text, round(max_prob, 4)  # âœ… ç›´æ¥è¿”å›ä¸¤ä¸ªå€¼
    except Exception as e:
        print(f"âŒ é”™è¯¯å‘ç”Ÿï¼š{e}")
        return "Error", 0.0  # âœ… ç¡®ä¿å§‹ç»ˆè¿”å›ä¸¤ä¸ªå€¼

# 7. Gradio æ¥å£
iface = gr.Interface(
    fn=predict_emotion,
    inputs=gr.File(file_count="single", type="filepath", label="ä¸Šä¼ çŒ«å«éŸ³é¢‘æ–‡ä»¶ (æ”¯æŒ .mp3, .wav, .mp4)"),
    outputs=[
        gr.Textbox(label="é¢„æµ‹æƒ…ç»ª"),
        gr.Number(label="é¢„æµ‹æ¦‚ç‡")
    ],
    title="ğŸ± çŒ«å«æƒ…ç»ªåˆ†ç±»",
    description="ğŸ“¢ ä¸Šä¼ çŒ«å«éŸ³é¢‘æ–‡ä»¶ï¼ˆwav, mp3 æˆ– mp4ï¼‰ï¼Œç³»ç»Ÿå°†è¿”å›é¢„æµ‹çš„æƒ…ç»ªç±»åˆ«å’Œæ¦‚ç‡ã€‚",
    theme="compact"
)

# 8. å¯åŠ¨ Web ç•Œé¢
if __name__ == "__main__":
    iface.launch(server_name="0.0.0.0", server_port=7860)
