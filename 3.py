import gradio as gr
import time
import joblib
import librosa
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import moviepy.editor as mp
import requests
import json
import os


# API ç›¸å…³é…ç½®
CHAT_URL = "https://api.coze.cn/v3/chat"
MESSAGE_LIST_URL = "https://api.coze.cn/v3/chat/message/list"
HEADERS = {
    "Authorization": "Bearer pat_vXDMjQzI98QKO9gUUN5nEU8YHZeu4v7heWMmjH4LFXzjpnA1o5Bmwvr2JCFVqond",
    "Content-Type": "application/json"
}

# åŠ è½½ YAMNet é¢„è®­ç»ƒæ¨¡å‹
local_model_path = "C:\\Users\\ç¾½è½\\.cache\\kagglehub\\models\\google\\yamnet\\tensorFlow2\\yamnet\\1"
yamnet_model = hub.load(local_model_path)

# åŠ è½½åˆ†ç±»æ¨¡å‹ & PCA å˜æ¢
model = joblib.load("voting_classifier.pkl")
pca = joblib.load("pca_transform.pkl")

# å®šä¹‰ç±»åˆ«æ˜ å°„
label_map = {
    0: "Angry",
    1: "Defence",
    2: "Fighting",
    3: "Happy",
    4: "HuntingMind",
    5: "Mating",
    6: "MotherCall",
    7: "Paining",
    8: "Resting",
    9: "Warning",
}

# å‘é€å¯¹è¯è¯·æ±‚
def send_chat_message(emotion):
    message = f"ä½œä¸ºä¸€åªæƒ…ç»ªç›®å‰æ˜¯{emotion}çš„çŒ«ï¼Œç»™æˆ‘ç¬¦åˆä½ æƒ…ç»ªçš„å›åº”ã€‚"
    data = {
        "bot_id": "7486346843451293708",
        "user_id": "123123***",
        "stream": False,
        "auto_save_history": True,
        "additional_messages": [
            {"role": "user", "content": message, "content_type": "text"}
        ]
    }
    response = requests.post(CHAT_URL, headers=HEADERS, json=data)
    if response.status_code == 200:
        response_data = response.json()
        if response_data.get("code") == 0:
            conversation_id = response_data.get("data", {}).get("conversation_id")
            chat_id = response_data.get("data", {}).get("id")
            if conversation_id and chat_id:
                return fetch_chat_messages(conversation_id, chat_id)
    return "API è°ƒç”¨å¤±è´¥"

# æŸ¥è¯¢å¯¹è¯æ¶ˆæ¯
def fetch_chat_messages(conversation_id, chat_id):
    params = {"conversation_id": conversation_id, "chat_id": chat_id}

    # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œç­‰å¾…3ç§’
    time.sleep(3)

    response = requests.get(MESSAGE_LIST_URL, headers=HEADERS, params=params)

    if response.status_code == 200:
        response_data = response.json()
        print("æŸ¥è¯¢æ¶ˆæ¯è¿”å›:", json.dumps(response_data, indent=2, ensure_ascii=False))

        # è§£æ API è¿”å›çš„æ¶ˆæ¯æ•°æ®
        if response_data.get("code") == 0:
            messages = response_data.get("data", [])  # è¿™é‡Œä¿®æ­£ï¼Œdata ç›´æ¥æ˜¯åˆ—è¡¨

            print("\nå¯¹è¯æ¶ˆæ¯è®°å½•ï¼š")
            # æ‰“å°å¹¶è¿”å›å¯¹è¯å†…å®¹
            for msg in messages:
                role = msg.get("role", "unknown")
                content = msg.get("content", "ï¼ˆæ— å†…å®¹ï¼‰")
                print(f"{role}: {content}")

            # è¿‡æ»¤æ‰ç±»å‹ä¸æ˜¯ "answer" çš„æ¶ˆæ¯
            filtered_messages = [
                msg["content"] for msg in messages 
                if "content" in msg and msg.get("type") == "answer"
            ]

            # è¿”å›å¤„ç†åçš„æ¶ˆæ¯å†…å®¹
            return "\n".join(filtered_messages) if filtered_messages else "æ²¡æœ‰æ‰¾åˆ°ç±»å‹ä¸º 'answer' çš„æ¶ˆæ¯"
        else:
            print(f"æŸ¥è¯¢å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {response_data.get('msg')}")
    else:
        print(f"è¯·æ±‚å¤±è´¥ï¼ŒHTTP çŠ¶æ€ç : {response.status_code}")
    
    return "æœªè·å–åˆ°èŠå¤©å†…å®¹"

# æå–éŸ³é¢‘ç‰¹å¾
def extract_features(file_path):
    audio, sr = librosa.load(file_path, sr=16000)
    waveform = tf.convert_to_tensor(audio, dtype=tf.float32)
    scores, embeddings, spectrogram = yamnet_model(waveform)
    feature = np.concatenate([
        tf.reduce_mean(embeddings, axis=0).numpy(),
        tf.reduce_max(embeddings, axis=0).numpy()
    ])
    feature = feature.reshape(1, -1)
    return pca.transform(feature)

# MP4 è½¬ MP3
def convert_mp4_to_mp3(mp4_path, output_path="temp_audio.mp3"):
    clip = mp.VideoFileClip(mp4_path).subclip(0, 4)
    clip.audio.write_audiofile(output_path, codec='mp3')
    return output_path

# é¢„æµ‹å‡½æ•°
def predict_emotion(audio_file_path):
    if audio_file_path.endswith(".mp4"):
        mp3_file_path = convert_mp4_to_mp3(audio_file_path)
    else:
        mp3_file_path = audio_file_path
    
    feature = extract_features(mp3_file_path)
    predicted_label_idx = model.predict(feature)[0]
    predicted_label_text = label_map.get(predicted_label_idx, "Unknown")
    api_response = send_chat_message(predicted_label_text)
    
    return predicted_label_text, api_response

# Gradio æ¥å£
iface = gr.Interface(
    fn=predict_emotion,
    inputs=gr.File(file_count="single", type="filepath", label="ä¸Šä¼ çŒ«å«éŸ³é¢‘æ–‡ä»¶"),
    outputs=[
        gr.Textbox(label="é¢„æµ‹æƒ…ç»ª"),
        gr.Textbox(label="API å“åº”")
    ],
    title="ğŸ± çŒ«å«æƒ…ç»ªåˆ†ç±»",
    description="ğŸ“¢ ä¸Šä¼ çŒ«å«éŸ³é¢‘æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è¿”å›é¢„æµ‹çš„æƒ…ç»ªç±»åˆ«ï¼Œå¹¶ä¸èŠå¤©æœºå™¨äººäº’åŠ¨ã€‚",
    theme="compact"
)

if __name__ == "__main__":
    iface.launch(server_name="0.0.0.0", server_port=7860)
