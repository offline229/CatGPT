import gradio as gr
import joblib
import librosa
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub

# 1. åŠ è½½ YAMNet é¢„è®­ç»ƒæ¨¡å‹
print("ğŸš€ åŠ è½½ YAMNet é¢„è®­ç»ƒæ¨¡å‹...")
local_model_path = "C:\\Users\\ç¾½è½\\.cache\\kagglehub\\models\\google\\yamnet\\tensorFlow2\\yamnet\\1"
yamnet_model = hub.load(local_model_path)
print("âœ… YAMNet åŠ è½½å®Œæˆï¼")

# 2. åŠ è½½åˆ†ç±»æ¨¡å‹ & PCA å˜æ¢
print("ğŸš€ åŠ è½½çŒ«å«åˆ†ç±»æ¨¡å‹ & PCA...")
model = joblib.load("voting_classifier.pkl")  # åŠ è½½å·²è®­ç»ƒå¥½çš„åˆ†ç±»å™¨
pca = joblib.load("pca_transform.pkl")  # åŠ è½½ PCA å˜æ¢
print("âœ… æ¨¡å‹ & PCA åŠ è½½æˆåŠŸï¼")

# 3. å®šä¹‰ç±»åˆ«æ˜ å°„
label_map = {
    0: "Angry",
    1: "Defence",
    2: "Fighting",
    3: "Happy",
    4: "HuntingMind",
    5: "Mating",
    6: "MotherCall",
    7: "Paining",
    8: "Resting",
    9: "Warning",
}

# 4. ç‰¹å¾æå–å‡½æ•°
def extract_features(file_path):
    """æå–éŸ³é¢‘ç‰¹å¾"""
    audio, sr = librosa.load(file_path, sr=16000)
    waveform = tf.convert_to_tensor(audio, dtype=tf.float32)
    scores, embeddings, spectrogram = yamnet_model(waveform)

    # **ä¿æŒå’Œè®­ç»ƒæ—¶ä¸€è‡´çš„ 2048 ç»´ç‰¹å¾**
    feature = np.concatenate([
        tf.reduce_mean(embeddings, axis=0).numpy(),
        tf.reduce_max(embeddings, axis=0).numpy()
    ])

    feature = feature.reshape(1, -1)  # ç¡®ä¿å½¢çŠ¶ä¸º (1, n)
    
    # **åº”ç”¨ PCA é™ç»´**
    feature = pca.transform(feature)  # è½¬æ¢ä¸º 256 ç»´
    return feature

# 5. é¢„æµ‹å‡½æ•°
def predict_emotion(audio_file_path):
    """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    try:
        feature = extract_features(audio_file_path)
        predicted_label_idx = model.predict(feature)[0]  # é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•
        probabilities = model.predict_proba(feature)[0]  # é¢„æµ‹çš„æ¦‚ç‡
        max_prob = max(probabilities)  # æœ€é«˜æ¦‚ç‡å€¼

        # è·å–ç±»åˆ«åç§°
        predicted_label_text = label_map.get(predicted_label_idx, "Unknown")

        return predicted_label_text, round(max_prob, 4)  # âœ… ç›´æ¥è¿”å›ä¸¤ä¸ªå€¼
    except Exception as e:
        return "Error", 0.0  # âœ… ç¡®ä¿å§‹ç»ˆè¿”å›ä¸¤ä¸ªå€¼


# 6. æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
# if __name__ == "__main__":
#    test_audio = "./CatSound/Resting/cat_coll0118.mp3"  # æ›¿æ¢æˆä½ çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
#    result = predict_emotion(test_audio)
#    print("ğŸ¯ é¢„æµ‹ç»“æœ:", result)
    
    
iface = gr.Interface(
    fn=predict_emotion,
    inputs=gr.Audio(type="filepath", label="ä¸Šä¼ çŒ«å«éŸ³é¢‘æ–‡ä»¶"),
    outputs=[
        gr.Textbox(label="é¢„æµ‹æƒ…ç»ª"),
        gr.Number(label="é¢„æµ‹æ¦‚ç‡")
    ],
    title="ğŸ± çŒ«å«æƒ…ç»ªåˆ†ç±»",
    description="ğŸ“¢ ä¸Šä¼ çŒ«å«éŸ³é¢‘æ–‡ä»¶ï¼ˆwav æˆ– mp3ï¼‰ï¼Œç³»ç»Ÿå°†è¿”å›é¢„æµ‹çš„æƒ…ç»ªç±»åˆ«å’Œæ¦‚ç‡ã€‚",
    theme="compact"
)

# 7ï¸âƒ£ **å¯åŠ¨ Web ç•Œé¢**
if __name__ == "__main__":
    iface.launch(server_name="0.0.0.0", server_port=7860)

